{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8KtuCBseIA48",
   "metadata": {
    "id": "8KtuCBseIA48"
   },
   "source": [
    "# Балансировка стаканов с компотом с помощью DQN-агента\n",
    "\n",
    "Работу выполнили студенты группы БСМО-11-25:\n",
    "\n",
    "* Аршинов Владислав\n",
    "* Елохин Валерий\n",
    "* Савин Даниил\n",
    "* Якушенко Иван\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5Lm7xWZ3jVxv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Lm7xWZ3jVxv",
    "outputId": "a01aa07a-b068-4ef4-8be9-507c066279bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: gymnasium in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: stable-baselines3 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from stable-baselines3) (2.9.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from stable-baselines3) (2.2.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3) (72.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from tensorboard) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from tensorboard) (3.8)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from tensorboard) (5.29.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cosmo\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3) (2025.2)\n"
     ]
    }
   ],
   "source": [
    "# Установка необходимых библиотек\n",
    "!pip install gymnasium stable-baselines3 matplotlib numpy tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b0ofJlCH5aK",
   "metadata": {
    "id": "6b0ofJlCH5aK"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6gyDmaPGIfoC",
   "metadata": {
    "id": "6gyDmaPGIfoC"
   },
   "outputs": [],
   "source": [
    "# Задаем параметры модели и ее обучения\n",
    "INITIAL_STATE = np.array([5, 3, 6, 2, 9], dtype=np.int32)     # Начальное состояние\n",
    "MAX_CAPACITY = np.max(INITIAL_STATE)                          # Максимальная емкость стакана\n",
    "TARGET_VOLUME = np.sum(INITIAL_STATE) // 5                    # Целевой объем\n",
    "MAX_STEPS = 200                                               # Максимальное число шагов в эпизоде\n",
    "TIMESTEPS_COUNT = 200000                                      # Число шагов обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6n_bkb3gIhUR",
   "metadata": {
    "id": "6n_bkb3gIhUR"
   },
   "source": [
    "Создадим среду для задачи.\n",
    "\n",
    "Наблюдение:\n",
    "- массив из 5 целых чисел, представляющих текущие объемы в стаканах.\n",
    "\n",
    "Каждое действие кодирует переливание из стакана A в стакан B:\n",
    "  - источник = действие // 4;\n",
    "  - цель = действие % 4, скорректированное так, чтобы не совпадать с источником.\n",
    "\n",
    "Награды:\n",
    "- -1 за первое действие или смену источника;\n",
    "- 0 за продолжение переливания из того же источника;\n",
    "- -10 за попытку невозможного действия;\n",
    "- +100 за успешное достижение баланса;\n",
    "- -100 за превышение лимита шагов.\n",
    "\n",
    "Завершение эпизода:\n",
    "- Все стаканы содержат целевой объем (успех);\n",
    "- Превышение лимита шагов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hJEs0HtEJ5h2",
   "metadata": {
    "id": "hJEs0HtEJ5h2"
   },
   "outputs": [],
   "source": [
    "class GlassesEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(GlassesEnv, self).__init__()\n",
    "\n",
    "        # Пространство наблюдений: 5 целых чисел от 0 до MAX_CAPACITY\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0,\n",
    "            high=MAX_CAPACITY,\n",
    "            shape=(5,),\n",
    "            dtype=np.int32\n",
    "        )\n",
    "\n",
    "        # Пространство действий: 5 источников * 4 цели = 20 действий\n",
    "        self.action_space = spaces.Discrete(20)\n",
    "\n",
    "        # Инициализация состояния\n",
    "        self.state = None\n",
    "        self.last_source = None  # Источник последнего успешного действия\n",
    "        self.steps = 0  # Счетчик шагов в эпизоде\n",
    "\n",
    "    def _decode_action(self, action):\n",
    "        \"\"\"Декодирование действия в источник и приемник\"\"\"\n",
    "        source = action // 4\n",
    "        target = action % 4\n",
    "\n",
    "        # Корректировка целевого стакана: пропускаем источник\n",
    "        target = target if target < source else target + 1\n",
    "        return source, target\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Сброс среды в начальное состояние\"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        self.state = INITIAL_STATE.copy()\n",
    "        self.last_source = None\n",
    "        self.steps = 0\n",
    "        return self.state.copy(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Выполнение шага среды\"\"\"\n",
    "        self.steps += 1\n",
    "        source, target = self._decode_action(action)\n",
    "\n",
    "        # Флаги для определения награды\n",
    "        invalid_action = False\n",
    "        done = False\n",
    "        truncated = False\n",
    "        success = False\n",
    "\n",
    "        # Проверка валидности действия\n",
    "        if self.state[source] <= 0 or self.state[target] >= MAX_CAPACITY:\n",
    "            invalid_action = True\n",
    "            reward = -10  # Штраф за невозможное действие\n",
    "        else:\n",
    "            # Выполнение переливания\n",
    "            new_state = self.state.copy()\n",
    "            new_state[source] -= 1\n",
    "            new_state[target] += 1\n",
    "            self.state = new_state\n",
    "\n",
    "            # Расчет награды за смену источника\n",
    "            if self.last_source is None:  # Первое действие в эпизоде\n",
    "                reward = -1\n",
    "                self.last_source = source\n",
    "            elif source == self.last_source:  # Тот же источник\n",
    "                reward = 0\n",
    "            else:  # Смена источника\n",
    "                reward = -1\n",
    "                self.last_source = source\n",
    "\n",
    "        # Проверка достижения цели\n",
    "        if np.all(self.state == TARGET_VOLUME):\n",
    "            done = True\n",
    "            success = True\n",
    "            reward += 100  # Награда за успех\n",
    "\n",
    "        # Проверка лимита шагов\n",
    "        if self.steps >= MAX_STEPS and not done:\n",
    "            truncated = True\n",
    "            done = True\n",
    "            reward = -100  # Штраф за превышение лимита\n",
    "\n",
    "        # Информация для отладки\n",
    "        info = {\n",
    "            'invalid_action': invalid_action,\n",
    "            'success': success,\n",
    "            'steps': self.steps\n",
    "        }\n",
    "\n",
    "        return self.state.copy(), reward, done, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "Ua4B0HKDLfHu",
   "metadata": {
    "id": "Ua4B0HKDLfHu"
   },
   "outputs": [],
   "source": [
    "# Callback для сбора статистики обучения\n",
    "class RewardLoggerCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(RewardLoggerCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.current_reward = 0\n",
    "        self.episode_count = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Получение информации о завершении эпизода из info\n",
    "        if 'terminal_observation' in self.locals['infos'][0]:\n",
    "            self.episode_rewards.append(self.current_reward)\n",
    "            self.current_reward = 0\n",
    "            self.episode_count += 1\n",
    "        else:\n",
    "            self.current_reward += self.locals['rewards'][0]\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "H_MH6k4rL8Tv",
   "metadata": {
    "id": "H_MH6k4rL8Tv"
   },
   "outputs": [],
   "source": [
    "# Создание среды\n",
    "env = GlassesEnv()\n",
    "\n",
    "# Инициализация DQN-агента\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=0,\n",
    "    buffer_size=32768,\n",
    "    learning_starts=1024,\n",
    "    batch_size=128,\n",
    "    gamma=0.99,\n",
    "    train_freq=4,\n",
    "    target_update_interval=1000,\n",
    "    exploration_fraction=0.3,\n",
    "    exploration_initial_eps=1.0,\n",
    "    exploration_final_eps=0.01,\n",
    "    gradient_steps=1,\n",
    "    tensorboard_log=\"./dqn_glasses_tensorboard/\"\n",
    ")\n",
    "\n",
    "# Callback для логирования наград\n",
    "reward_logger = RewardLoggerCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "RFJF9F7QMKzW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "referenced_widgets": [
      "8b36af9cfec04f6696870cbc5f763e7d",
      "12c4361561b64a79924fc14f2d333cbe"
     ]
    },
    "id": "RFJF9F7QMKzW",
    "outputId": "ac9c1912-a0f6-4bd0-c408-87347347fc19"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62584b660cea48fda2c03e7dcc94970d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x134576bcb90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучение агента\n",
    "model.learn(\n",
    "    total_timesteps=TIMESTEPS_COUNT,\n",
    "    callback=reward_logger,\n",
    "    progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c6aebe0-7829-4456-be23-8104d9abf2e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c6aebe0-7829-4456-be23-8104d9abf2e4",
    "outputId": "3ccd14c6-d696-40ab-c974-13f2e7bb311c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Демонстрация работы обученного агента:\n",
      "Шаг 1: Действие: 5->4, Состояние: [5 3 6 3 8], Награда: -1\n",
      "Шаг 2: Действие: 5->4, Состояние: [5 3 6 4 7], Награда: 0\n",
      "Шаг 3: Действие: 5->4, Состояние: [5 3 6 5 6], Награда: 0\n",
      "Шаг 4: Действие: 5->2, Состояние: [5 4 6 5 5], Награда: 0\n",
      "Шаг 5: Действие: 5->2, Состояние: [5 5 6 5 4], Награда: 0\n",
      "Шаг 6: Действие: 3->5, Состояние: [5 5 5 5 5], Награда: 99\n",
      "\n",
      "Эпизод завершен! Итоговая награда: 98.00\n",
      "Количество шагов: 6\n",
      "Финальное состояние: [5 5 5 5 5]\n",
      "Успех: Да\n"
     ]
    }
   ],
   "source": [
    "# Демонстрация работы обученного агента\n",
    "print(\"Демонстрация работы обученного агента:\")\n",
    "obs, _ = env.reset()\n",
    "total_reward = 0\n",
    "step_count = 0\n",
    "\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    step_count += 1\n",
    "\n",
    "    print(f\"Шаг {step_count}: Действие: {1 + action//4}->{1 + action%4 + bool(action%4 > action//4)}, Состояние: {obs}, Награда: {reward}\")\n",
    "\n",
    "    if terminated or truncated:\n",
    "        print(f\"\\nЭпизод завершен! Итоговая награда: {total_reward:.2f}\")\n",
    "        print(f\"Количество шагов: {step_count}\")\n",
    "        print(f\"Финальное состояние: {obs}\")\n",
    "        success = np.all(obs == TARGET_VOLUME)\n",
    "        print(f\"Успех: {'Да' if success else 'Нет'}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f126bf5d-1af9-460e-bda6-392dc7cf59f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кривая обучения сохранена в 'learning_curve.html'\n"
     ]
    }
   ],
   "source": [
    "# Генерация кривой обучения с использованием Plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Создаём интерактивный график\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=reward_logger.episode_rewards,\n",
    "    mode='lines+markers',\n",
    "    name='Награда за эпизод',\n",
    "    line=dict(width=2),\n",
    "    marker=dict(size=4)\n",
    "))\n",
    "\n",
    "# Настройка макета\n",
    "fig.update_layout(\n",
    "    title='Кривая обучения: Награда за эпизод',\n",
    "    xaxis_title='Номер эпизода',\n",
    "    yaxis_title='Суммарная награда',\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "# Сохранение в HTML-файл\n",
    "fig.write_html('learning_curve.html')\n",
    "print(\"Кривая обучения сохранена в 'learning_curve.html'\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "12c4361561b64a79924fc14f2d333cbe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b36af9cfec04f6696870cbc5f763e7d": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_12c4361561b64a79924fc14f2d333cbe",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">999,920/1,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:21:06</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">746 it/s</span> ]\n</pre>\n",
          "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m999,920/1,000,000 \u001b[0m [ \u001b[33m0:21:06\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m746 it/s\u001b[0m ]\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
